{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Cython==0.28.2 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from -r requirements.txt (line 1)) (0.28.2)\n",
      "Requirement already satisfied: imutils==0.5.3 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from -r requirements.txt (line 2)) (0.5.3)\n",
      "Requirement already satisfied: matplotlib==2.2.2 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from -r requirements.txt (line 3)) (2.2.2)\n",
      "Requirement already satisfied: numpy==1.14.3 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from -r requirements.txt (line 4)) (1.14.3)\n",
      "Requirement already satisfied: numpydoc==0.8.0 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from -r requirements.txt (line 5)) (0.8.0)\n",
      "Requirement already satisfied: opencv-contrib-python==4.4.0.42 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from -r requirements.txt (line 6)) (4.4.0.42)\n",
      "Requirement already satisfied: pandas==0.23.0 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from -r requirements.txt (line 7)) (0.23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from matplotlib==2.2.2->-r requirements.txt (line 3)) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from matplotlib==2.2.2->-r requirements.txt (line 3)) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from matplotlib==2.2.2->-r requirements.txt (line 3)) (2.7.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from matplotlib==2.2.2->-r requirements.txt (line 3)) (2018.4)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from matplotlib==2.2.2->-r requirements.txt (line 3)) (1.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from matplotlib==2.2.2->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: sphinx>=1.2.3 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from numpydoc==0.8.0->-r requirements.txt (line 5)) (1.7.4)\n",
      "Requirement already satisfied: Jinja2>=2.3 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from numpydoc==0.8.0->-r requirements.txt (line 5)) (2.10)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from Jinja2>=2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (1.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib==2.2.2->-r requirements.txt (line 3)) (39.1.0)\n",
      "Requirement already satisfied: Pygments>=2.0 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (2.2.0)\n",
      "Requirement already satisfied: docutils>=0.11 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (0.14)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (1.2.1)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (2.5.3)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (0.7.10)\n",
      "Requirement already satisfied: imagesize in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (2.18.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (17.1)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (1.0.1)\n",
      "Requirement already satisfied: colorama>=0.3.5 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (0.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from requests>=2.0.0->sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from requests>=2.0.0->sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from requests>=2.0.0->sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shravani\\miniconda3\\envs\\py35\\lib\\site-packages (from requests>=2.0.0->sphinx>=1.2.3->numpydoc==0.8.0->-r requirements.txt (line 5)) (2018.4.16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Python 3.5 reached the end of its life on September 13th, 2020. Please upgrade your Python as Python 3.5 is no longer maintained. pip 21.0 will drop support for Python 3.5 in January 2021. pip 21.0 will remove support for this functionality.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Object tracking algorithms for Multi object tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tracker(trackertype):\n",
    "    trackers_dict = {'BOOSTING' : cv2.TrackerBoosting_create(),\n",
    "                 'MIL' : cv2.TrackerMIL_create(), \n",
    "                 'KCF' : cv2.TrackerKCF_create(),\n",
    "                 'TLD' : cv2.TrackerTLD_create(), \n",
    "                 'MEDIANFLOW' : cv2.TrackerMedianFlow_create(), \n",
    "                 'GOTURN' : cv2.TrackerGOTURN_create(), \n",
    "                 'MOSSE' : cv2.TrackerMOSSE_create(), \n",
    "                 'CSRT' : cv2.TrackerCSRT_create()}\n",
    "    if trackertype in trackers_dict.keys():\n",
    "        tracker = trackers_dict[trackertype]\n",
    "        \n",
    "    else :\n",
    "        tracker = None\n",
    "        print('Incorrect tracker name')\n",
    "        print('Available trackers :')\n",
    "        for key in trackers_dict.keys():\n",
    "            print(key)\n",
    "    return tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Face detector and eye dector from haarcascades\n",
    "* Haarcascades download link reference : https://github.com/opencv/opencv/tree/master/data/haarcascades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions to detect the pupil of eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_params = cv2.SimpleBlobDetector_Params()\n",
    "detector_params.filterByArea = True\n",
    "\n",
    "def eyes_blob(face , threshold):\n",
    "    grey_face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "    grey_face = cv2.medianBlur(grey_face, 5)\n",
    "    eyes = eye_cascade.detectMultiScale(grey_face)\n",
    "    for (x1,y1,w1,h1) in eyes:\n",
    "        area = w1*h1\n",
    "        detector_params.minArea = area/12\n",
    "        detector_params.maxArea =  area/5\n",
    "        detector = cv2.SimpleBlobDetector_create(detector_params)\n",
    "        cv2.rectangle(face,(x1,y1),(x1+w1,y1+h1),(0,255,0),2)\n",
    "        eye = face[int(y1):int(y1+h1), int(x1):int(x1+w1)]\n",
    "        grey_eye = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
    "        ret, grey_eye = cv2.threshold(grey_eye, threshold, 255, cv2.THRESH_BINARY)\n",
    "        #grey_eye = cv2.GaussianBlur(grey_eye,(5,5),0)\n",
    "        grey_eye = cv2.erode(grey_eye, None, iterations=2) #1\n",
    "        #grey_eye = cv2.dilate(grey_eye, None, iterations=4) #2\n",
    "        grey_eye = cv2.medianBlur(grey_eye, 5)\n",
    "        keypoints = detector.detect(grey_eye)\n",
    "        if keypoints :\n",
    "            print(threshold,area, keypoints[0].pt[0],keypoints[0].pt[1])\n",
    "        cv2.drawKeypoints(eye, keypoints, eye, (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "def get_blobs(eye , threshold, area):\n",
    "    detector_params.minArea = area/12\n",
    "    detector_params.maxArea =  area/5\n",
    "    detector = cv2.SimpleBlobDetector_create(detector_params)\n",
    "    grey_eye = cv2.cvtColor(eye, cv2.COLOR_BGR2GRAY)\n",
    "    ret, grey_eye = cv2.threshold(grey_eye, threshold, 255, cv2.THRESH_BINARY)\n",
    "    grey_eye = cv2.medianBlur(grey_eye, 5)\n",
    "    grey_eye = cv2.erode(grey_eye, None, iterations=2) #1\n",
    "    #grey_eye = cv2.dilate(grey_eye, None, iterations=4)\n",
    "    keypoints = detector.detect(grey_eye)\n",
    "    if keypoints :\n",
    "        #print(threshold,area, keypoints[0].pt[0],keypoints[0].pt[1], keypoints[0].size)\n",
    "        key_x,key_y,key_dia = keypoints[0].pt[0],keypoints[0].pt[1], keypoints[0].size\n",
    "        cv2.drawKeypoints(eye, keypoints, eye, (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        return key_x,key_y,key_dia\n",
    "    \n",
    "def get_blob_track():\n",
    "        xl,yl,wl,hl = left_eye\n",
    "        l_eye = img[yl:yl+hl, xl:xl+wl]\n",
    "        area = wl*hl\n",
    "        t = 5\n",
    "        while (True):\n",
    "            a = get_blobs(l_eye , t, area)\n",
    "            if a is not None:\n",
    "                #print(a)\n",
    "                key_x,key_y,l_dia = a\n",
    "                #bbox = (int(xl+key_x-l_dia/2),int(yl+key_y-l_dia/2),int(l_dia),int(l_dia))\n",
    "                #multiTracker.add(createTrackerByName(trackerType), img, bbox)\n",
    "                break\n",
    "            t += 1\n",
    "        t1 = t\n",
    "        xl,yl,wl,hl = right_eye\n",
    "        r_eye = img[yl:yl+hl, xl:xl+wl]\n",
    "        area = wl*hl\n",
    "        t = 5\n",
    "        while (True):\n",
    "            a = get_blobs(r_eye , t, area)\n",
    "            if a is not None:\n",
    "                key_x,key_y,r_dia = a\n",
    "                #bbox = (int(xl+key_x-r_dia/2),int(yl+key_y-r_dia/2),int(r_dia),int(r_dia))\n",
    "                #multiTracker.add(createTrackerByName(trackerType), img, bbox)\n",
    "                break\n",
    "            t += 1\n",
    "        t2 = t\n",
    "        return [t1,t2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face and eye detection method\n",
    "**Pupil detection method :** Blobs are detected on the eyes detected from the detected faces. \n",
    "\n",
    "**Advantages:**\n",
    "* Faces and eyes are detected in every frame so it doesn't loose track of the eyes and faces.\n",
    "* This method works very accurately for high resolution webcams/ camera.\n",
    "* starts detecting any new faces in the frame\n",
    "\n",
    "**Limitations:**\n",
    "* For low resolution cameras, the discontinuity in face and eye detection can be identified.\n",
    "* If the eye detection accuracy is low the pupil detection becomes extremely difficult\n",
    "* Threshold value varies for different lighting conditions, this should be set manually\n",
    "\n",
    "\n",
    "**Please note that threshold should be set manually using the trackerbar in this method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 1681 12.89159870147705 22.976152420043945\n",
      "28 1600 16.733333587646484 22.700000762939453\n",
      "28 1681 15.490078926086426 25.83333396911621\n",
      "29 1521 16.42831802368164 22.31563377380371\n",
      "29 961 8.057971000671387 19.004140853881836\n",
      "29 1681 16.473039627075195 22.476102828979492\n",
      "27 1225 10.762300491333008 20.466388702392578\n",
      "32 1764 16.85236358642578 23.24336814880371\n",
      "26 1444 8.853994369506836 22.891183853149414\n",
      "26 1444 12.095041275024414 22.479339599609375\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def nothing(x):\n",
    "    pass\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('image')\n",
    "cv2.createTrackbar('threshold', 'image', 0, 255, nothing)\n",
    "while(True):\n",
    "    threshold = cv2.getTrackbarPos('threshold', 'image')\n",
    "    ret, img = cap.read()\n",
    "    gray_picture = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_picture = cv2.medianBlur(gray_picture, 7)\n",
    "    faces = face_cascade.detectMultiScale(gray_picture, 1.3, 5)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "        face_left = img[int(y):int(y+h//2), int(x):int(x+w//2)]\n",
    "        face_right = img[int(y):int(y+h//2), int(x+w//2):int(x+w)]\n",
    "        eyes_blob(face_left , threshold)\n",
    "        eyes_blob(face_right , threshold)\n",
    "    cv2.imshow(\"image\", img)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually selecting Eye regions for detection\n",
    "\n",
    "**Pupil detection method :** Blobs are detected on the selected eye tracking regions. \n",
    "\n",
    "**Advantages:**\n",
    "* Works very fast as we are not detecting on each frame (Speed depends on the type of tracker which is being used\n",
    "* Works even on the low resolution cameras.\n",
    "\n",
    "**Limitations:**\n",
    "* Eye regions should be selected manually\n",
    "* The tracking of the pupil completely depends on the region of selection accuracy\n",
    "* Threshold should be set manually\n",
    "\n",
    "**Please note that threshold should be set manually using the trackerbar in this method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the eye bounding boxes\n",
      "Press any key to select next object\n",
      "(262, 176, 68, 43)\n",
      "(365, 186, 43, 40)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def nothing(x):\n",
    "    pass\n",
    "trackerType = 'CSRT'\n",
    "multiTracker = cv2.MultiTracker_create()\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('image')\n",
    "k = 0\n",
    "colors = [(0,255,0),(0,255,0)]\n",
    "bboxes = []\n",
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    if k == 0:\n",
    "        cv2.imshow(\"image\", img)\n",
    "        print('Select the eye bounding boxes')\n",
    "        while(True):\n",
    "            bbox = cv2.selectROI('image', img)\n",
    "            bboxes.append(bbox)\n",
    "            colors.append((randint(64, 255), randint(64, 255), randint(64, 255)))\n",
    "            m = cv2.waitKey(0) & 0xFF\n",
    "            if len(bboxes) == 2:\n",
    "                break\n",
    "            else:\n",
    "                print(\"Press any key to select next object\")\n",
    "        multiTracker = cv2.MultiTracker_create()\n",
    "\n",
    "        # Initialize MultiTracker \n",
    "        #print(len(bbox))\n",
    "        for bbox in bboxes:\n",
    "            print(bbox)\n",
    "            multiTracker.add(create_tracker(trackerType), img, bbox)\n",
    "        k=1\n",
    "        cv2.createTrackbar('threshold', 'image', 0, 255, nothing)\n",
    "    threshold = cv2.getTrackbarPos('threshold', 'image')\n",
    "    (success, boxes) = multiTracker.update(img)\n",
    "    \n",
    "    #print(len(boxes))\n",
    "    #success1,face_bbox = tracker1.update(img)\n",
    "    if not success:\n",
    "        print('Failed')\n",
    "    if success:\n",
    "        for i, newbox in enumerate(boxes):\n",
    "            #print(i,newbox)\n",
    "            xi,yi,wi,hi = int(newbox[0]),int(newbox[1]),int(newbox[2]),int(newbox[3])\n",
    "            cv2.rectangle(img, (xi,yi),(xi+wi,yi+hi), colors[i], 2, 1)\n",
    "            if i > 0 :\n",
    "                eye = img[yi:yi+hi, xi:xi+wi]\n",
    "                area = wi*hi\n",
    "                get_blobs(eye , threshold, area)\n",
    "            \n",
    "    cv2.imshow(\"image\", img)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face and Eye detection and Tracking\n",
    "Face and eye detection **Haarcascades** are used to detect face and eyes\n",
    "\n",
    "**Pupil detection method :** Blobs are detected on the selected eye tracking regions. \n",
    "\n",
    "**Advantages:**\n",
    "* Works very fast as we are not detecting on each frame (Speed depends on the type of tracker which is being used)\n",
    "* Works even on the low resolution cameras.\n",
    "\n",
    "**Limitations:**\n",
    "* Threshold should be set manually\n",
    "* Sometimes same threshold value doesnt work for both the eye regions\n",
    "\n",
    "**Please note that threshold should be set manually using the trackerbar in this method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "(218, 94, 196, 196)\n",
      "(245, 136, 54, 54)\n",
      "(333, 138, 50, 50)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def nothing(x):\n",
    "    pass\n",
    "# CSRT tracker is used as the accuracy is higher, KCF tracker can be used for faster detection\n",
    "trackerType = 'CSRT'\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow('image')\n",
    "k = 0\n",
    "s = 0\n",
    "threshold = 0\n",
    "colors = [(255,255,0),(0,255,0),(0,255,0),(0,0,255),(0,0,255)]\n",
    "cv2.createTrackbar('threshold', 'image', 0, 255, nothing)\n",
    "while(True):\n",
    "    threshold = cv2.getTrackbarPos('threshold', 'image')\n",
    "    while k < 4:\n",
    "        ret, img = cap.read()\n",
    "        cv2.imshow(\"image\", img)\n",
    "        c = cv2.waitKey(1)\n",
    "        k = 0\n",
    "        multiTracker = cv2.MultiTracker_create()\n",
    "        bboxes = []\n",
    "        ret, img = cap.read()\n",
    "        gray_picture = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray_picture = cv2.medianBlur(gray_picture, 7)\n",
    "        faces = face_cascade.detectMultiScale(gray_picture, 1.3, 5)\n",
    "        if len(faces) > 0:\n",
    "            face_bbox = (faces[0][0],faces[0][1],faces[0][2],faces[0][3])\n",
    "            (x,y,w,h) = face_bbox\n",
    "            bboxes.append(face_bbox)\n",
    "            k+=1\n",
    "        \n",
    "        face_left = img[int(y):int(y+h//2), int(x):int(x+w//2)]\n",
    "        grey_face = cv2.cvtColor(face_left, cv2.COLOR_BGR2GRAY)\n",
    "        grey_face = cv2.medianBlur(grey_face, 5)\n",
    "        eyes = eye_cascade.detectMultiScale(grey_face)\n",
    "        if len(eyes) > 0:\n",
    "            left_eye = (eyes[0][0]+x,eyes[0][1]+y,eyes[0][2],eyes[0][3])\n",
    "            bboxes.append(left_eye)\n",
    "            k+=1\n",
    "        \n",
    "        face_right = img[int(y):int(y+h//2), int(x+w//2):int(x+w)]\n",
    "        grey_face = cv2.cvtColor(face_right, cv2.COLOR_BGR2GRAY)\n",
    "        grey_face = cv2.medianBlur(grey_face, 5)\n",
    "        eyes = eye_cascade.detectMultiScale(grey_face)\n",
    "        if len(eyes) > 0:\n",
    "            right_eye = (eyes[0][0]+x+w//2,eyes[0][1]+y,eyes[0][2],eyes[0][3])\n",
    "            bboxes.append(right_eye)\n",
    "            k+=1\n",
    "        \n",
    "        if k == 3:\n",
    "            for bbox in bboxes:\n",
    "                print(bbox)\n",
    "                multiTracker.add(create_tracker(trackerType), img, bbox)\n",
    "            #thr = get_blob_track()\n",
    "            k+=1\n",
    "        print(k)\n",
    "        \n",
    "    ret, img = cap.read()\n",
    "    success, boxes = multiTracker.update(img)\n",
    "    \n",
    "    #print(len(boxes))\n",
    "    #success1,face_bbox = tracker1.update(img)\n",
    "    if not success:\n",
    "        s += 1\n",
    "        if s >= 30:\n",
    "            k = 0\n",
    "    if success:\n",
    "        s = 0\n",
    "        for i, newbox in enumerate(boxes):\n",
    "            xi,yi,wi,hi = int(newbox[0]),int(newbox[1]),int(newbox[2]),int(newbox[3])\n",
    "            cv2.rectangle(img, (xi,yi),(xi+wi,yi+hi), colors[i], 2, 1)\n",
    "            if i > 0 :\n",
    "                eye = img[yi+hi//10:yi+hi, xi:xi+wi]\n",
    "                area = wi*hi\n",
    "                try:\n",
    "                    get_blobs(eye , threshold, area)\n",
    "                except:\n",
    "                    next\n",
    "        \n",
    "        #x,y,w,h = int(face_bbox[0]),int(face_bbox[1]),int(face_bbox[2]),int(face_bbox[3])\n",
    "        #cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    cv2.imshow(\"image\", img)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face and Eye detection and Tracking - Adaptive thresholding\n",
    "This method is similar to the previous method, except that threshold is calculated automatically.\n",
    "\n",
    "**Pupil detection method :** Blobs are detected on the selected eye tracking regions. \n",
    "\n",
    "**Advantages:**\n",
    "* Works very fast as we are not detecting on each frame (Speed depends on the type of tracker which is being used)\n",
    "* Works even on the low resolution cameras.\n",
    "* Threshold values will be calculated automatically for each eye\n",
    "\n",
    "**Limitations:**\n",
    "* Fast movement of face might cause in losing the tracking\n",
    "\n",
    "**Please note that threshold should be set manually using the trackerbar in this method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 21, 223, 223)\n",
      "(252, 82, 46, 46)\n",
      "(342, 84, 42, 42)\n",
      "[7, 9]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "def nothing(x):\n",
    "    pass\n",
    "trackerType = 'CSRT'\n",
    "cap = cv2.VideoCapture(0)\n",
    "k = 0\n",
    "s = 0\n",
    "threshold = 0\n",
    "colors = [(255,255,0),(0,255,0),(0,255,0),(0,0,255),(0,0,255)]\n",
    "while(True):\n",
    "    #threshold = cv2.getTrackbarPos('threshold', 'image')\n",
    "    while k < 4:\n",
    "        ret, img = cap.read()\n",
    "        cv2.imshow(\"image\", img)\n",
    "        c = cv2.waitKey(1)\n",
    "        k = 0\n",
    "        multiTracker = cv2.MultiTracker_create()\n",
    "        bboxes = []\n",
    "        gray_picture = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        gray_picture = cv2.medianBlur(gray_picture, 7)\n",
    "        faces = face_cascade.detectMultiScale(gray_picture, 1.3, 5)\n",
    "        if len(faces) > 0:\n",
    "            face_bbox = (faces[0][0],faces[0][1],faces[0][2],faces[0][3])\n",
    "            (x,y,w,h) = face_bbox\n",
    "            bboxes.append(face_bbox)\n",
    "            k+=1\n",
    "        \n",
    "        face_left = img[int(y):int(y+h//2), int(x):int(x+w//2)]\n",
    "        grey_face = cv2.cvtColor(face_left, cv2.COLOR_BGR2GRAY)\n",
    "        grey_face = cv2.medianBlur(grey_face, 5)\n",
    "        eyes = eye_cascade.detectMultiScale(grey_face)\n",
    "        if len(eyes) > 0:\n",
    "            left_eye = (eyes[0][0]+x,eyes[0][1]+y,eyes[0][2],eyes[0][3])\n",
    "            bboxes.append(left_eye)\n",
    "            k+=1\n",
    "        \n",
    "        face_right = img[int(y):int(y+h//2), int(x+w//2):int(x+w)]\n",
    "        grey_face = cv2.cvtColor(face_right, cv2.COLOR_BGR2GRAY)\n",
    "        grey_face = cv2.medianBlur(grey_face, 5)\n",
    "        eyes = eye_cascade.detectMultiScale(grey_face)\n",
    "        if len(eyes) > 0:\n",
    "            right_eye = (eyes[0][0]+x+w//2,eyes[0][1]+y,eyes[0][2],eyes[0][3])\n",
    "            bboxes.append(right_eye)\n",
    "            k+=1\n",
    "        \n",
    "        if k == 3:\n",
    "            for bbox in bboxes:\n",
    "                print(bbox)\n",
    "                multiTracker.add(create_tracker(trackerType), img, bbox)\n",
    "            thr = get_blob_track()\n",
    "            print(thr)\n",
    "            k+=1\n",
    "        print(k)\n",
    "        \n",
    "    ret, img = cap.read()\n",
    "    success, boxes = multiTracker.update(img)\n",
    "    if not success:\n",
    "        s += 1\n",
    "        if s >= 30:\n",
    "            k = 0\n",
    "    if success:\n",
    "        s = 0\n",
    "        for i, newbox in enumerate(boxes):\n",
    "            xi,yi,wi,hi = int(newbox[0]),int(newbox[1]),int(newbox[2]),int(newbox[3])\n",
    "            cv2.rectangle(img, (xi,yi),(xi+wi,yi+hi), colors[i], 2, 1)\n",
    "            if i > 0 :\n",
    "                eye = img[yi+hi//10:yi+hi, xi:xi+wi]\n",
    "                area = wi*hi\n",
    "                try:\n",
    "                    get_blobs(eye , thr[i-1]+3, area)\n",
    "                except:\n",
    "                    next\n",
    "    cv2.imshow(\"image\", img)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References :**\n",
    "1. https://medium.com/@stepanfilonov/tracking-your-eyes-with-python-3952e66194a6\n",
    "2. https://www.learnopencv.com/multitracker-multiple-object-tracking-using-opencv-c-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
